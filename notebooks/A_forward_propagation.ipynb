{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing forward propagation through a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements forward propagation through a simple neural network. The network architecture consists of:\n",
    "\n",
    "1. **Input Layer**: 2 units, taking a vector x ∈ ℝ²\n",
    "2. **Hidden Layer**: 2 units with ReLU activation\n",
    "   - Linear transformation: z₁ = W₁x + b₁\n",
    "   - ReLU activation: a₁ = max(0, z₁)\n",
    "3. **Output Layer**: 2 units with softmax activation\n",
    "   - Linear transformation: z₂ = W₂a₁ + b₂\n",
    "   - Softmax activation: y = softmax(z₂)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation is broken down into these key components:\n",
    "\n",
    "1. **Linear Forward**: Implements the affine transformation z = Wx + b\n",
    "2. **ReLU Activation**: Implements the element-wise ReLU function max(0,x)\n",
    "3. **Softmax Activation**: Converts raw scores into probabilities\n",
    "4. **Forward Pass**: Combines all components for full forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(x, W, b):\n",
    "    \"\"\"\n",
    "    Implements linear forward propagation: z = Wx + b\n",
    "    Args:\n",
    "        x: input vector (n,)\n",
    "        W: weight matrix (m,n)\n",
    "        b: bias vector (m,)\n",
    "    Returns:\n",
    "        z: output vector (m,)\n",
    "    \"\"\"\n",
    "    return np.dot(W, x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))  # Subtract max for numerical stability\n",
    "    return exp_z / np.sum(exp_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, W1, b1, W2, b2):\n",
    "    # First layer\n",
    "    z1 = linear_forward(x, W1, b1)\n",
    "    a1 = relu(z1)\n",
    "    \n",
    "    # Second layer\n",
    "    z2 = linear_forward(a1, W2, b2)\n",
    "    output = softmax(z2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Your Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Running all unit tests...\n",
      "\n",
      "🔍 Testing: linear_forward...\n",
      "✅ linear_forward passed!\n",
      "🔍 Testing: relu...\n",
      "✅ relu passed!\n",
      "🔍 Testing: softmax...\n",
      "✅ softmax passed!\n",
      "🔍 Testing: forward_pass...\n",
      "✅ forward_pass passed!\n",
      "\n",
      "🎉 All tests completed!\n"
     ]
    }
   ],
   "source": [
    "def test_linear_forward():\n",
    "    print(\"🔍 Testing: linear_forward...\")\n",
    "    x = np.array([1.0, 2.0])\n",
    "    W = np.array([[1.0, -1.0], [0.5, 2.0]])\n",
    "    b = np.array([0.0, 1.0])\n",
    "    result = linear_forward(x, W, b)\n",
    "    \n",
    "    expected = np.array([-1.0, 5.5])\n",
    "    \n",
    "    assert isinstance(result, np.ndarray), \"❌ Output is not a NumPy array.\"\n",
    "    assert result.shape == expected.shape, f\"❌ Expected shape {expected.shape}, got {result.shape}\"\n",
    "    assert np.allclose(result, expected), f\"❌ Incorrect values: expected {expected}, got {result}\"\n",
    "    print(\"✅ linear_forward passed!\")\n",
    "\n",
    "\n",
    "def test_relu():\n",
    "    print(\"🔍 Testing: relu...\")\n",
    "    z = np.array([-1.0, 0.0, 2.5])\n",
    "    result = relu(z)\n",
    "    expected = np.array([0.0, 0.0, 2.5])\n",
    "    \n",
    "    assert np.allclose(result, expected), f\"❌ ReLU failed: expected {expected}, got {result}\"\n",
    "    print(\"✅ relu passed!\")\n",
    "\n",
    "\n",
    "def test_softmax():\n",
    "    print(\"🔍 Testing: softmax...\")\n",
    "    z = np.array([1.0, 2.0, 3.0])\n",
    "    result = softmax(z)\n",
    "    expected = np.exp(z) / np.sum(np.exp(z))\n",
    "    \n",
    "    assert np.allclose(result, expected, atol=1e-6), \"❌ Softmax values are incorrect.\"\n",
    "    assert np.isclose(np.sum(result), 1.0), \"❌ Softmax output does not sum to 1.\"\n",
    "    print(\"✅ softmax passed!\")\n",
    "\n",
    "\n",
    "def test_forward_pass():\n",
    "    print(\"🔍 Testing: forward_pass...\")\n",
    "    x = np.array([1.0, 2.0])\n",
    "    W1 = np.array([[1.0, -1.0], [0.5, 2.0]])\n",
    "    b1 = np.array([0.0, 1.0])\n",
    "    W2 = np.array([[1.0, 2.0], [-1.0, 1.0]])\n",
    "    b2 = np.array([0.0, 0.0])\n",
    "    \n",
    "    output = forward_pass(x, W1, b1, W2, b2)\n",
    "\n",
    "    assert isinstance(output, np.ndarray), \"❌ Output must be a NumPy array.\"\n",
    "    assert output.shape == (2,), f\"❌ Expected output shape (2,), got {output.shape}\"\n",
    "    assert np.isclose(np.sum(output), 1.0, atol=1e-6), \"❌ Output probabilities must sum to 1.\"\n",
    "    assert np.all(output >= 0), \"❌ Output contains negative probabilities.\"\n",
    "    print(\"✅ forward_pass passed!\")\n",
    "\n",
    "\n",
    "# Run all tests\n",
    "def run_all_tests():\n",
    "    print(\"🏁 Running all unit tests...\\n\")\n",
    "    test_linear_forward()\n",
    "    test_relu()\n",
    "    test_softmax()\n",
    "    test_forward_pass()\n",
    "    print(\"\\n🎉 All tests completed!\")\n",
    "\n",
    "# Call this to test all at once:\n",
    "run_all_tests()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
